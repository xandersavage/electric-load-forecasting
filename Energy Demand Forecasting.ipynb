{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a47d5597-dbec-4504-8be7-0edd717b2412",
   "metadata": {},
   "source": [
    "# ENERGY LOAD FORECASTING PROJECT\n",
    "Comparing Facebook Prophet vs SARIMAX for Hourly Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835c4dbe-a3c9-44cf-924f-903abbc33e29",
   "metadata": {},
   "source": [
    "PROJECT OVERVIEW\n",
    "================\n",
    "In this project, I'm building a time series forecasting model to predict \n",
    "hourly electricity load (demand) in Italy for 2016. \n",
    "\n",
    "Why is this important?\n",
    "- Energy grid operators need accurate load predictions to manage supply\n",
    "- Solar generation affects net load (more solar = less grid demand)\n",
    "- Accurate forecasts prevent blackouts and reduce costs\n",
    "\n",
    "I'll compare two powerful forecasting methods:\n",
    "1. Facebook Prophet - Great for handling seasonality automatically\n",
    "2. SARIMAX - Classical statistical approach with external variables\n",
    "\n",
    "Let's get started! üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2135345-32c6-45b9-bca6-f3d3913a1eaa",
   "metadata": {
    "tags": []
   },
   "source": [
    "# SECTION 1: ENVIRONMENT SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c1e9d9-f6cd-422f-8ee4-3fc07764e08e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"SECTION 1: INSTALLING PACKAGES AND SETTING UP ENVIRONMENT\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba53b24-b0f2-4fd4-b85c-31d1bd0a9644",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# I'm installing all the packages I'll need for this project\n",
    "# This might take a minute, so be patient!\n",
    "\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# Install required packages\n",
    "print(\"\\nüì¶ Installing required packages...\")\n",
    "packages = [\n",
    "    'pandas',\n",
    "    'numpy', \n",
    "    'matplotlib',\n",
    "    'plotly',\n",
    "    'statsmodels',\n",
    "    'prophet',\n",
    "    'pmdarima',  # For auto_arima\n",
    "    'scikit-learn'\n",
    "]\n",
    "\n",
    "for package in packages:\n",
    "    try:\n",
    "        __import__(package)\n",
    "        print(f\"‚úì {package} already installed\")\n",
    "    except ImportError:\n",
    "        print(f\"Installing {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package])\n",
    "        print(f\"‚úì {package} installed successfully\")\n",
    "\n",
    "print(\"\\n‚úì All packages ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c919dd27-884e-46b8-b11f-6f832b87d8b5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# SECTION 2: IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbb4c17-890f-4d25-a328-70d28e18436b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SECTION 2: IMPORTING LIBRARIES\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2d5d7c-31bc-4393-bdbb-7714b9a7442f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# I'm importing all the necessary libraries for data manipulation, \n",
    "# visualization, and modeling\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # Hide warnings for cleaner outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3dd7b1-c260-4c86-baaf-e52e459ab09a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Time series specific imports\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from prophet import Prophet\n",
    "from pmdarima import auto_arima\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5366479-7d28-43aa-8277-3654b4e49e4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Metrics for model evaluation\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "print(\"‚úì All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b260d745-6cfa-4403-8b5b-bb0ef841a802",
   "metadata": {},
   "source": [
    "# SECTION 3: LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0290bb9f-c3da-43e2-ba64-22e2fb110757",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SECTION 3: LOADING THE DATASET\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a3da43-6e0a-4b8f-af9b-b08f9c4d3b78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# NOTE: Replace this path with your actual file path\n",
    "# For Google Colab, you can mount Google Drive like this:\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# file_path = '/content/drive/MyDrive/IT_2016_Hourly_Energy.csv'\n",
    "\n",
    "# For local use or if file is in same directory:\n",
    "file_path = r\"YOUR_FILE_PATH\"\n",
    "\n",
    "print(f\"\\nüìÇ Loading data from: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047ad040-6d09-4a92-b0e7-aef0562881fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# I'm loading the dataset and immediately converting the timestamp column \n",
    "# to a proper datetime format so Python understands it's a date/time\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(file_path, parse_dates=['utc_timestamp'])\n",
    "    print(\"‚úì Data loaded successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå File not found! Please check the file path.\")\n",
    "    print(\"Creating sample data for demonstration...\")\n",
    "    \n",
    "    # Create sample data for demonstration if file not found\n",
    "    dates = pd.date_range('2016-01-01', '2016-12-31 23:00:00', freq='H')\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Create synthetic load data with daily and weekly patterns\n",
    "    hours = np.array([d.hour for d in dates])\n",
    "    days = np.array([d.dayofweek for d in dates])\n",
    "    \n",
    "    # Base load with trend\n",
    "    base_load = 30000 + np.linspace(0, 5000, len(dates))\n",
    "    \n",
    "    # Daily pattern (higher during day)\n",
    "    daily_pattern = 8000 * np.sin((hours - 6) * np.pi / 12)\n",
    "    \n",
    "    # Weekly pattern (lower on weekends)\n",
    "    weekly_pattern = -2000 * (days >= 5).astype(int)\n",
    "    \n",
    "    # Random noise\n",
    "    noise = np.random.normal(0, 1000, len(dates))\n",
    "    \n",
    "    load = base_load + daily_pattern + weekly_pattern + noise\n",
    "    load = np.maximum(load, 15000)  # Ensure minimum load\n",
    "    \n",
    "    # Solar generation (inverse of load during day)\n",
    "    solar = np.maximum(0, 5000 * np.sin((hours - 6) * np.pi / 12) + \n",
    "                       np.random.normal(0, 500, len(dates)))\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'utc_timestamp': dates,\n",
    "        'IT_load_new': load,\n",
    "        'IT_solar_generation': solar\n",
    "    })\n",
    "    \n",
    "    print(\"‚úì Sample data created for demonstration!\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d00fa08-ca4d-4c3e-9782-442f2745930b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set timestamp as index for easier time series operations\n",
    "df.set_index('utc_timestamp', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9284c2cc-1140-4797-b0ab-e42563eca486",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display basic information about the dataset\n",
    "print(f\"\\nüìä Dataset Information:\")\n",
    "print(f\"   -Shape: {df.shape[0]} rows x {df.shape[1]} columns\")\n",
    "print(f\"   -Date Range: {df.index.min()} to {df.index.max()}\")\n",
    "print(f\"   - Frequency: Hourly\")\n",
    "print(f\"\\n   First few rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3028ac19-00a1-4985-9902-979db0d5b9b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"\\n   Summary Statistics:\")\n",
    "print(df.describe().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b3bb9c-cdeb-44f6-972c-a78b6fdf7010",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "print(f\"\\n   Missing Values:\")\n",
    "print(missing_values)\n",
    "\n",
    "if missing_values.sum() > 0:\n",
    "    print(\"\\n‚ö† I found missing values! I'll handle them in the next step.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b40c1fd-8e9e-4c15-9e9a-db78b3c35b09",
   "metadata": {},
   "source": [
    "# SECTION 4: DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470758a3-7efb-4e99-ba8b-45376063dc19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SECTION 4: DATA PREPROCESSING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nüîß Cleaning and preparing the data...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4263ad3e-893c-4a1f-8aa5-13e6ba1d5031",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Handle missing values if they exist\n",
    "if df.isnull().sum().sum() > 0:\n",
    "    print(\"\\n   Handling missing values...\")\n",
    "    print(\"   Strategy: Forward fill then backward fill\")\n",
    "    print(\"   Why? This preserves the time series pattern better than dropping rows\")\n",
    "    df = df.fillna(method='ffill').fillna(method='bfill')\n",
    "    print(\"   ‚úì Missing values handled!\")\n",
    "else:\n",
    "    print(\"   ‚úì No missing values found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d9eb25-14b0-4179-80e2-495dde51f108",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "missing_values = df.isnull().sum()\n",
    "print(f\"\\n   Missing Values:\")\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2108b154-59cb-47f3-b3a9-1f4aa72ca831",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Rename columns for clarity in visualizations\n",
    "df_original = df.copy()   # Keep original for SARIMAX\n",
    "df.columns = ['Load_MW', 'Solar_MW']\n",
    "\n",
    "print(f\"\\n‚úì Data preprocessing complete!\")\n",
    "print(f\"   Final dataset shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183ee8e3-fa0f-4c3c-ae10-c3e76284ba0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47e62d9-b6a6-48a9-a83e-a8f36809772b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e85909-2081-4a1d-a6d6-164f0b1047e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d873bd40-f69f-4915-bf9c-af141cf98420",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "type(df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551ca161-eb2c-4492-b558-0bc0a5136cba",
   "metadata": {},
   "source": [
    "# SECTION 5: EXPLORATORY DATA ANALYSIS (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4501ba37-46c7-479d-84ee-8d8e5149023a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SECTION 5: EXPLORATORY DATA ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nüìä Let's visualize the data to understand patterns...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54597fa5-a003-4826-9073-e3c8b8c41558",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 5.1: Time Series Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1aabcb-7290-4167-a433-27335d05fa06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"\\n[5.1] Creating Time Series Overview Plot...\")\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=1,\n",
    "    subplot_titles=('Electricity Load (Demand) Over Time', \n",
    "                    'Solar Generation Over Time'),\n",
    "    vertical_spacing=0.1\n",
    ")\n",
    "\n",
    "# Load plot\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=df.index, y=df['Load_MW'], \n",
    "               name='Load', \n",
    "               line=dict(color='royalblue', width=1)),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "#Solar plot\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=df.index, y=df['Solar_MW'], name='Solar',\n",
    "              line=dict(color='orange', width=1)),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "fig.update_xaxes(title_text='Date', row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"Load (MW)\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Solar (MW)\", row=2, col=1)\n",
    "\n",
    "fig.update_layout(\n",
    "    height=600,\n",
    "    title_text=\"Italy 2016 - Hourly Energy Data Overview\",\n",
    "    showlegend=True,\n",
    "    hovermode='x unified'\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(\"‚úì Time series overview created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85da070-8ff5-430c-9706-e7294a8f4004",
   "metadata": {},
   "source": [
    "### 5.2: Seasonal Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07db8588-4331-42b0-a8b4-06829836b8c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"\\n[5.2] Performing Seasonal Decomposition...\")\n",
    "print(\"This breaks down the time series into: Trend + Seasonal + Residual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd55605-626c-4dfe-be1c-27d22559b1fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "decomposition = seasonal_decompose(df['Load_MW'], model='additive', period=24)\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=4, cols=1,\n",
    "    subplot_titles=\n",
    "    ('Original Load', 'Trend', 'Seasonal (12 Months)', 'Residual'),\n",
    "    vertical_spacing=0.1\n",
    ")\n",
    "\n",
    "# Original\n",
    "fig.add_trace(go.Scatter(x=df.index, y=df['Load_MW'],\n",
    "                        line=dict(color='blue', width=1),\n",
    "                        name='Original'),\n",
    "             row=1, col=1)\n",
    "\n",
    "# Trend\n",
    "fig.add_trace(go.Scatter(x=df.index, y=decomposition.trend, \n",
    "                         line=dict(color='red', width=2), name='Trend'),\n",
    "              row=2, col=1)\n",
    "\n",
    "# Seasonal\n",
    "fig.add_trace(go.Scatter(x=df.index, y=decomposition.seasonal, \n",
    "                         line=dict(color='green', width=1), name='Seasonal'),\n",
    "              row=3, col=1)\n",
    "\n",
    "# Residual\n",
    "fig.add_trace(go.Scatter(x=df.index, y=decomposition.resid, \n",
    "                         line=dict(color='gray', width=1), name='Residual'),\n",
    "              row=4, col=1)\n",
    "\n",
    "fig.update_layout(height=800, title_text=\"Time Series Decomposition\", showlegend=False)\n",
    "fig.show()\n",
    "\n",
    "print(\"‚úì Decomposition complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36622473-7c92-4de4-8766-4827676e060b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **Key Findings on Electricity Load (`Load_MW` - Demand)**\n",
    "\n",
    "I noticed that electricity demand is primarily driven by seasonal and calendar effects:\n",
    "\n",
    "1.  **Dual Seasonality:** The load peaks significantly in two distinct periods, reflecting the use of climate control:\n",
    "    * **Winter Peaks (Jan, Nov, Dec):** Driven by **heating** demand.\n",
    "    * **Summer Peaks (Jul):** Driven by **air conditioning** (cooling) demand.\n",
    "2.  **Calendar Effects (Holiday Dips):** I observed sharp, sudden drops in demand that are critical to note:\n",
    "    * **Mid-August Dip:** This aligns perfectly with the ***Ferragosto*** national holiday period in Italy, where much of the commercial and industrial load shuts down.\n",
    "    * **Other Dips:** Smaller but noticeable drops in **April, October, and December** are likely due to other national holidays (like Easter) and the Christmas/New Year's holiday period.\n",
    "\n",
    "> **‚û°Ô∏è Actionable Insight:** Since these holiday dips are predictable, I will use **Prophet's holiday feature** to explicitly model them. This prevents the model from interpreting them as random noise, which would ruin the forecast for a regular weekday.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Findings on Solar Generation (`Solar_MW` - Exogenous Variable)**\n",
    "\n",
    "The solar plot confirms its function as a vital external predictor for my model:\n",
    "\n",
    "1.  **Physical Trend:** The plot shows a clear, inverse U-shaped curve, peaking around the summer months (June/July). This is simply driven by **physics**: the longest, most intense daylight hours occur in the summer.\n",
    "2.  **Inverse Correlation:** As expected, the Solar Generation is a *counterweight* to the Load. During sunny hours, local generation meets some demand, causing the net demand on the central grid (`Load_MW`) to fall.\n",
    "\n",
    "> **‚û°Ô∏è Actionable Insight:** I must include the `Solar_MW` column as an **exogenous variable (regressor)** in both the Prophet and SARIMAX models to capture this vital relationship and maximize forecast accuracy.\n",
    "\n",
    "---\n",
    "\n",
    "### **Critical Data Anomaly Found** üö®\n",
    "\n",
    "I discovered a major issue around the end of October that requires immediate attention:\n",
    "\n",
    "* **Massive Spike (Oct 29-31):** The Solar Generation plot shows an extreme, unphysical spike. In energy time series, this is the classic signature of an error related to the **Daylight Saving Time (DST)** transition, where an hour is duplicated or miscalculated.\n",
    "\n",
    "> **‚û°Ô∏è Actionable Insight:** This spike is a powerful outlier. Before fitting either model, I must perform **data cleaning** to **impute or remove** this handful of corrupted data points. Ignoring it would severely skew the parameters of the SARIMAX model and negatively impact the performance of Prophet.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5657603-c8ab-4d0a-af22-9083335a0b68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filter the Solar_MW data for October to mid-November 2016\n",
    "# This window ensures we capture the anomaly and the clean data around it.\n",
    "solar_oct_nov = df['Solar_MW'].loc['2016-10-01':'2016-11-15']\n",
    "\n",
    "# Create the Plotly visualization\n",
    "fig = go.Figure()\n",
    "\n",
    "# 1. Plot the Solar MW time series\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=solar_oct_nov.index,\n",
    "    y=solar_oct_nov.values,\n",
    "    mode='lines',\n",
    "    name='Solar Generation (MW)',\n",
    "    line=dict(color='orange', width=2)\n",
    "))\n",
    "\n",
    "# 2. Add vertical lines for the previous anomaly boundary estimates (for reference)\n",
    "# These were the estimates (2016-10-29 to 2016-11-01) that might have been slightly off.\n",
    "max_y = solar_oct_nov.max() if not solar_oct_nov.empty else 10000\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Solar Generation (MW) - Anomaly Detection Window (Oct-Nov 2016)',\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='Solar Generation (MW)',\n",
    "    height=600,\n",
    "    shapes=[\n",
    "        # Previous Start Estimate: 2016-10-29\n",
    "        dict(\n",
    "            type=\"line\",\n",
    "            x0='2016-10-29', y0=0, x1='2016-10-29', y1=max_y,\n",
    "            line=dict(color=\"Red\", width=1, dash=\"dot\"),\n",
    "        ),\n",
    "        # Previous End Estimate: 2016-11-01\n",
    "        dict(\n",
    "            type=\"line\",\n",
    "            x0='2016-11-01', y0=0, x1='2016-11-01', y1=max_y,\n",
    "            line=dict(color=\"Red\", width=1, dash=\"dot\"),\n",
    "        )\n",
    "    ],\n",
    "    annotations=[\n",
    "        dict(x='2016-10-29', y=max_y * 0.95, xref=\"x\", yref=\"y\", \n",
    "             text=\"Previous Start Estimate\", showarrow=False, font=dict(color=\"Red\")),\n",
    "        dict(x='2016-11-01', y=max_y * 0.90, xref=\"x\", yref=\"y\", \n",
    "             text=\"Previous End Estimate\", showarrow=False, font=dict(color=\"Red\"))\n",
    "    ]\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e65bbc-2730-4f37-a1f4-4eb5ab16099b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the exact window identified by visual inspection\n",
    "anomaly_start = '2016-10-27 00:00:00'\n",
    "anomaly_end = '2016-11-01 00:00:00' \n",
    "\n",
    "print(\"SECTION: FINAL DST Anomaly Repair (Linear Interpolation)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. Capture the original, corrupted data for inspection\n",
    "original_solar = df['Solar_MW'].loc[anomaly_start:anomaly_end].copy()\n",
    "original_load = df['Load_MW'].loc[anomaly_start:anomaly_end].copy()\n",
    "\n",
    "# 2. ISOLATION: Temporarily set the outlier values to NaN\n",
    "df.loc[anomaly_start:anomaly_end, 'Load_MW'] = np.nan\n",
    "df.loc[anomaly_start:anomaly_end, 'Solar_MW'] = np.nan\n",
    "\n",
    "# 3. INTERPOLATION (The Fix): Apply the safer 'linear' method directly\n",
    "# Linear interpolation prevents the \"overshoot\" that caused negative solar values.\n",
    "df['Load_MW'] = df['Load_MW'].interpolate(method='linear')\n",
    "df['Solar_MW'] = df['Solar_MW'].interpolate(method='linear')\n",
    "\n",
    "# 4. Extract the newly imputed values for verification\n",
    "imputed_solar = df['Solar_MW'].loc[anomaly_start:anomaly_end]\n",
    "imputed_load = df['Load_MW'].loc[anomaly_start:anomaly_end]\n",
    "\n",
    "\n",
    "print(f\"‚úÖ Anomaly Window successfully repaired using LINEAR interpolation: {anomaly_start} to {anomaly_end}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Create a comparison table for inspection\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Original Solar (MW)': original_solar,\n",
    "    'Imputed Solar (MW)': imputed_solar,\n",
    "    'Original Load (MW)': original_load,\n",
    "    'Imputed Load (MW)': imputed_load\n",
    "}).dropna(subset=['Original Solar (MW)'])\n",
    "\n",
    "print(\"\\nSample of Imputed Values (Now Linear) vs. Corrupted Values:\")\n",
    "print(comparison_df.head(10).round(2))\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f569ebc6-d113-4f62-bfd4-93a1200f4677",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"\\n[5.1] Creating Time Series Overview Plot...\")\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=1,\n",
    "    subplot_titles=('Electricity Load (Demand) Over Time', \n",
    "                    'Solar Generation Over Time'),\n",
    "    vertical_spacing=0.1\n",
    ")\n",
    "\n",
    "# Load plot\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=df.index, y=df['Load_MW'], \n",
    "               name='Load', \n",
    "               line=dict(color='royalblue', width=1)),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "#Solar plot\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=df.index, y=df['Solar_MW'], name='Solar',\n",
    "              line=dict(color='orange', width=1)),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "fig.update_xaxes(title_text='Date', row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"Load (MW)\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Solar (MW)\", row=2, col=1)\n",
    "\n",
    "fig.update_layout(\n",
    "    height=600,\n",
    "    title_text=\"Italy 2016 - Hourly Energy Data Overview (After outlier treatment)\",\n",
    "    showlegend=True,\n",
    "    hovermode='x unified'\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(\"‚úì Time series overview created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f36a85-317d-4f15-81e3-55c01cf9db44",
   "metadata": {},
   "source": [
    "### 5.3: Daily Pattern Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ec1b40-cb41-4a5b-a8e2-b168f45dc8bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"\\n[5.3] Creating Daily Pattern Heatmap...\")\n",
    "print(\"This shows average load by hour and day of week\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b88944-e2c9-43b4-bae5-180cb6d6af47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create hour and day columns\n",
    "df_heatmap = df.copy()  # I'm creating a copy of the main data so I don't accidentally change the original.\n",
    "df_heatmap['Hour'] = df_heatmap.index.hour\n",
    "df_heatmap['DayOfWeek'] = df_heatmap.index.dayofweek\n",
    "df_heatmap['DayName'] = df_heatmap.index.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0834bfd-ff52-43a2-9dfc-d99203000419",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abd8178-9a0e-47b4-bb8d-567405b7695e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate the average load by hour and day\n",
    "pivot_table = df_heatmap.pivot_table(\n",
    "    values='Load_MW',\n",
    "    index='DayName',\n",
    "    columns='Hour',\n",
    "    aggfunc='mean'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a6ff35-817e-4fe4-b28e-4f55564004e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pivot_table.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e2d223-0020-490d-9c7f-564db4ddd946",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reorder days correctly\n",
    "day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "pivot_table = pivot_table.reindex(day_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993419b7-a92f-475c-99a0-ecec5d1e55d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = go.Figure(data=go.Heatmap(\n",
    "    z=pivot_table.values,\n",
    "    x=pivot_table.columns,\n",
    "    y=pivot_table.index,\n",
    "    colorscale='RdYlBu_r',\n",
    "    colorbar=dict(title=\"Load (MW)\")\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Average Hourly Load Pattern by Day of Week',\n",
    "    xaxis_title='Hour of Day',\n",
    "    yaxis_title='Day of Week',\n",
    "    height=500\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(\"‚úì Heatmap created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce5ca6b-197e-4242-85aa-4846e0cd5030",
   "metadata": {},
   "source": [
    "### 5.4: Load vs Solar Relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ae9ccf-d88c-4eff-b9b8-6a2bb4af0509",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"\\n[5.4] Analyzing Load vs Solar Generation Relationship...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e4f597-ee79-4640-be57-bc1e64f0cb49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a temporary DataFrame for normalized values\n",
    "df_norm = df[['Load_MW', 'Solar_MW']].copy()\n",
    "\n",
    "# Normalize the data between 0 and 1 (Min-Max Scaling)\n",
    "# This allows us to plot them on the same vertical scale for comparison\n",
    "for col in df_norm.columns:\n",
    "    df_norm[col] = (df_norm[col] - df_norm[col].min()) / (df_norm[col].max() - df_norm[col].min())\n",
    "\n",
    "# Create the plot using normalized data\n",
    "fig = go.Figure()\n",
    "\n",
    "# Load Trace (Blue)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_norm.index, y=df_norm['Load_MW'],\n",
    "    name='Load (Normalized)',\n",
    "    line=dict(color='royalblue', width=1)\n",
    "))\n",
    "\n",
    "# Solar Trace (Orange) - Inverted to show the direct opposite trend\n",
    "# We invert the solar data (1 - value) to show how it negatively impacts the load.\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_norm.index, y=1 - df_norm['Solar_MW'],\n",
    "    name='Solar (Inverted & Normalized)',\n",
    "    line=dict(color='orange', width=1, dash='dot')\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Load vs. Inverted Solar (Normalized)',\n",
    "    yaxis_title='Normalized Scale (0-1)',\n",
    "    xaxis_title='Date',\n",
    "    height=500,\n",
    "    hovermode='x unified'\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(\"\\nInsight:\")\n",
    "print(\"The lines mirror each other, clearly showing the inverse relationship. When the inverted solar line (orange) is high, the load line (blue) is also high, demonstrating that when *actual* solar is low, load is high.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6f4077-5c09-4fe7-8255-0d3a74784a71",
   "metadata": {},
   "source": [
    "# SECTION 6: TRAIN-TEST SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f89bc6-eafd-4f47-8198-ba076a43bde6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SECTION 6: SPLITTING DATA INTO TRAIN AND TEST SETS\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c129eb2-8ded-48f4-995a-3c7663b1d30f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"\\n‚úÇÔ∏è Splitting data for model evaluation...\")\n",
    "print(\"Strategy: Use last 30 days (720 hours) for testing\")\n",
    "print(\"Why? This represents a realistic forecasting horizon for energy planning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7d0e77-9ba2-46fb-81d3-4f50e9cea56b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate split point (last 30 days = 720 hours)\n",
    "test_size = 30 * 24  # 30 days x 24 hours\n",
    "split_index = len(df) - test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172e6840-225b-4aaa-b2e9-f61397c5d50e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split the data\n",
    "train_df = df.iloc[:split_index]\n",
    "test_df = df.iloc[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e8de77-93a6-411a-b9d2-fd2bbe3064cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"\\nüìä Split Summary:\")\n",
    "print(f\"   Training Set: {len(train_df)} hours ({len(train_df)//24} days)\")\n",
    "print(f\"   Test Set: {len(test_df)} hours ({len(test_df)//24} days)\")\n",
    "print(f\"   Train Period: {train_df.index.min()} to {train_df.index.max()}\")\n",
    "print(f\"   Test Period: {test_df.index.min()} to {test_df.index.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70e6473-44cc-46fe-85f8-029089b25601",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualize the split\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=train_df.index, y=train_df['Load_MW'],\n",
    "    name='Training Data', line=dict(color='blue', width=1)))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=test_df.index, y=test_df['Load_MW'],\n",
    "    name='Test Data', line=dict(color='red', width=1)\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Train-Test Split Visualization',\n",
    "    height=800,\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='Load (MW)'\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(\"‚úì Data split complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2101f6-63cc-4bf2-b68c-ab8211bf9ccf",
   "metadata": {},
   "source": [
    "# SECTION 7: FACEBOOK PROPHET MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74360090-72b7-49d6-b396-2dcead2b9b8d",
   "metadata": {
    "tags": []
   },
   "source": [
    "üîÆ What is Prophet?\n",
    "   - Developed by Facebook (Meta) for forecasting at scale\n",
    "   - Automatically handles multiple seasonalities (daily, weekly, yearly)\n",
    "   - Great for business time series with strong seasonal patterns\n",
    "   - Can include external regressors (like solar generation!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fe3cf8-d650-4743-82bc-e1bfdf370112",
   "metadata": {},
   "source": [
    "### 7.1: Prepare Data for Prophet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea44ed2-7db2-483c-b784-9b14337d3bbe",
   "metadata": {
    "tags": []
   },
   "source": [
    "Preparing data for Prophet...\n",
    "\n",
    "Prophet requires specific column names: 'ds' (date) and 'y' (target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ae320e-6bec-47af-8c95-6909eaf69ab5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create Prophet dataframe\n",
    "prophet_train = pd.DataFrame({\n",
    "    'ds': train_df.index,\n",
    "    'y': train_df['Load_MW'].values,\n",
    "    'solar': train_df['Solar_MW']   # External regressor\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b8a4eb-e321-4210-ab17-23b640faa799",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prophet_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063a3afc-b1c7-45f2-b286-f72afe9f06a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prophet_test = pd.DataFrame({\n",
    "    'ds': test_df.index,\n",
    "    'solar': test_df['Solar_MW'].values  # Need solar for predictions\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8762637f-f114-46f7-91e3-837696d0015c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"‚úì Data prepared!\")\n",
    "print(f\"   Training samples: {len(prophet_train)}\")\n",
    "print(f\"   Test samples: {len(prophet_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd6a317-9d7f-4983-acab-d32a5fa05bba",
   "metadata": {},
   "source": [
    "### 7.2: Configure and Train Prophet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317caa21-15f1-4091-81ea-63cd18904882",
   "metadata": {
    "tags": []
   },
   "source": [
    "Configuring and training Prophet model...\n",
    "\n",
    "Configuration:\n",
    "   - Daily seasonality: ON (24-hour patterns)\n",
    "   - Weekly seasonality: ON (weekday vs weekend)\n",
    "   - Yearly seasonality: ON (seasonal changes)\n",
    "   - Adding 'solar' as external regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1a8b2a-3b71-47e3-a626-6e82b8a0417a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize Prophet with configurations\n",
    "# prophet_model = Prophet(\n",
    "#     daily_seasonality=True,\n",
    "#     weekly_seasonality=True,\n",
    "#     yearly_seasonality=True,\n",
    "#     seasonality_mode='additive',\n",
    "#     interval_width=0.95\n",
    "# )\n",
    "\n",
    "prophet_model = Prophet()\n",
    "\n",
    "# Add solar generation as external regressor\n",
    "prophet_model.add_regressor('solar')\n",
    "\n",
    "# Automatically include italian national holidays\n",
    "prophet_model.add_country_holidays(country_name='IT')\n",
    "print(\"   - Added national holidays for Italy ('IT')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cf512e-bf62-4d14-a0f2-02b779912427",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Before fitting, ensure the 'ds' column is timezone-naive\n",
    "# This is a mandatory step for Prophet if your data has timezone info\n",
    "if prophet_train['ds'].dt.tz is not None:\n",
    "    prophet_train['ds'] = prophet_train['ds'].dt.tz_localize(None)\n",
    "    print(\"‚úÖ Removed timezone from 'ds' column.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4b4748-9345-4ef3-9b19-4aed6dcac131",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prophet_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41457e7c-9d68-4dbb-bb74-0c9ca9c2dc88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"\\n‚è≥ Training Prophet model... (this may take a minute)\")\n",
    "# Fit the model\n",
    "prophet_model.fit(prophet_train)\n",
    "print(\"‚úì Prophet model trained successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f620259-ea6a-4ad6-96b0-bc7305c3dde0",
   "metadata": {},
   "source": [
    "### 7.3: Make Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc88eae-0fd0-468f-b305-2014a2322759",
   "metadata": {
    "tags": []
   },
   "source": [
    "Generating Prophet forecasts...\n",
    "\n",
    "NOTE: You MUST also remove the timezone from the future/test dataframe!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33320349-daaf-4619-81ec-1de9870c090c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "future = prophet_test.copy()\n",
    "if future['ds'].dt.tz is not None:\n",
    "    future['ds'] = future['ds'].dt.tz_localize(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d0120f-08ff-4b5c-b900-8971500709be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "prophet_forecast = prophet_model.predict(future)\n",
    "print(\"‚úì Forecasts generated!\")\n",
    "print(f\"   Forecast columns available: {list(prophet_forecast.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df35871-2f8f-42be-b70a-9f18acab4447",
   "metadata": {},
   "source": [
    "### 7.4: Visualize Prophet Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8734979-29fc-452b-8110-8b515f2342aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "# Actual test data\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=test_df.index,\n",
    "    y=test_df['Load_MW'],\n",
    "    name='Actual Load',\n",
    "    line=dict(color='black', width=2)\n",
    "))\n",
    "\n",
    "# Prophet prediction\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=prophet_forecast['ds'],\n",
    "    y=prophet_forecast['yhat'],\n",
    "    name='Prophet Forecast',\n",
    "    line=dict(color='blue', width=2, dash='dash')\n",
    "))\n",
    "\n",
    "# Confidence interval\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=prophet_forecast['ds'],\n",
    "    y=prophet_forecast['yhat_upper'],\n",
    "    fill=None,\n",
    "    mode='lines',\n",
    "    line=dict(color='lightblue', width=0),\n",
    "    showlegend=False\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=prophet_forecast['ds'],\n",
    "    y=prophet_forecast['yhat_lower'],\n",
    "    fill='tonexty',\n",
    "    mode='lines',\n",
    "    line=dict(color='lightblue', width=0),\n",
    "    name='95% Confidence Interval'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Prophet Forecast vs Actual Load (30-Day Test Period)',\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='Load (MW)',\n",
    "    hovermode='x unified',\n",
    "    height=500\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(\"‚úì Visualization complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06eeec98-9b47-49c4-bc78-7a6a24b41791",
   "metadata": {},
   "source": [
    "### 7.5: Prophet Components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e748d1c-d823-4723-9e43-4137c71b8fdd",
   "metadata": {
    "tags": []
   },
   "source": [
    "Analyzing Prophet components...\n",
    "\n",
    "This shows how each factor contributes to the forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e4c62d-4277-4090-b749-ea899e9d6339",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot components\n",
    "fig_components = prophet_model.plot_components(prophet_forecast)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5895b6d-8a8d-478e-9d91-67e6d7cb3af2",
   "metadata": {},
   "source": [
    "# SECTION 8: SARIMAX MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b6b94d-9d56-4d0f-9f22-a07bc85f174a",
   "metadata": {
    "tags": []
   },
   "source": [
    "üìà What is SARIMAX?\n",
    "   - Seasonal AutoRegressive Integrated Moving Average with eXogenous variables\n",
    "   - Classical statistical approach for time series\n",
    "   - Explicitly models seasonality with seasonal parameters\n",
    "   - Can include external variables (exogenous regressors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66398113-a9f4-47e6-875d-6f0d16b676fa",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 8.1: Find Optimal Parameters with auto_arima"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a426014-9d07-4eed-9654-20cda04a749f",
   "metadata": {
    "tags": []
   },
   "source": [
    "Finding optimal SARIMAX parameters...\n",
    "\n",
    "I'm using auto_arima to automatically find the best parameters\n",
    "\n",
    "This tests many combinations and picks the best based on AIC\n",
    "\n",
    "‚è≥ This might take several minutes... grab a coffee! ‚òï"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf37bad-c6d3-48ca-b7a4-2e6d4b438bb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Use auto_arima to find optimal parameters\n",
    "# # I'm limiting the search space to keep it manageable for beginners (myself)\n",
    "\n",
    "# stepwise_model = auto_arima(\n",
    "#     train_df['Load_MW'],\n",
    "#     exogenous=train_df[['Solar_MW']],\n",
    "#     seasonal=True,\n",
    "#     m=24,  # Seasonal period (24 hours)\n",
    "#     max_p=3,  # Max AR order\n",
    "#     max_q=3,  # Max MA order\n",
    "#     max_P=2,  # Max seasonal AR\n",
    "#     max_Q=2,  # Max seasonal MA\n",
    "#     max_d=1,  # Max differencing\n",
    "#     max_D=1,  # Max seasonal differencing\n",
    "#     trace=True,  # Print progress\n",
    "#     error_action='ignore',\n",
    "#     suppress_warnings=True,\n",
    "#     stepwise=True,  # Use stepwise algorithm (faster)\n",
    "# )\n",
    "\n",
    "# print(\"\\n‚úì Optimal parameters found!\")\n",
    "# print(f\"\\nBest Model: {stepwise_model.order} √ó {stepwise_model.seasonal_order}\")\n",
    "# print(f\"AIC: {stepwise_model.aic():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1032639-f8c9-4869-a780-df52fd6b2449",
   "metadata": {},
   "source": [
    "### 8.2: Train SARIMAX with Optimal Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6800b63f-44aa-42c9-8073-a47704ab263d",
   "metadata": {
    "tags": []
   },
   "source": [
    "Training SARIMAX model with optimal parameters..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225d2556-5948-4c52-8b43-14c13571699a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Build SARIMAX model\n",
    "# sarimax_model = SARIMAX(\n",
    "#     train_df['Load_MW'],\n",
    "#     exog=train_df[['Solar_MW']],\n",
    "#     order=stepwise_model.order,\n",
    "#     seasonal_order=stepwise_model.seasonal_order,\n",
    "#     enforce_stationarity=False,\n",
    "#     enforce_invertibility=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198e4d47-620e-43a7-bebf-0eba0392c9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build SARIMAX model\n",
    "sarimax_model = SARIMAX(\n",
    "    train_df['Load_MW'],\n",
    "    exog=train_df[['Solar_MW']],\n",
    "    # Hardcoding the optimal non-seasonal order (p, d, q)\n",
    "    order=(2, 1, 1),\n",
    "    # Hardcoding the optimal seasonal order (P, D, Q, m)\n",
    "    seasonal_order=(1, 0, 1, 24),\n",
    ")\n",
    "\n",
    "# NOTE: Since the parameters are hardcoded, you can skip the 'stepwise_model.fit()' \n",
    "# call and move directly to fitting the sarimax_model:\n",
    "# sarimax_results = sarimax_model.fit(disp=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219ddf93-3674-4093-852d-d17ce09ccc7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "print(\"‚è≥ Fitting SARIMAX model...\")\n",
    "sarimax_fitted = sarimax_model.fit(disp=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c72f63-7ca9-4bca-8998-b7b0e789fb33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"‚úì SARIMAX model trained successfully!\")\n",
    "print(\"\\nModel Summary:\")\n",
    "print(sarimax_fitted.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e35c523-a58f-4224-9fee-2fd1d7ba7421",
   "metadata": {},
   "source": [
    "### 8.3: Make SARIMAX Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1708ebdf-f880-4142-ab55-b2af6441b320",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "sarimax_forecast = sarimax_fitted.forecast(\n",
    "    steps=len(test_df),\n",
    "    exog=test_df[['Solar_MW']]\n",
    ")\n",
    "\n",
    "print(\"‚úì SARIMAX forecasts generated!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055add2e-8e88-42c5-81a8-341c8eebe3b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sarimax_forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd846b58-421a-4229-bddf-a4097f8a0feb",
   "metadata": {},
   "source": [
    "### 8.4: Visualize SARIMAX Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6cf7dc-1e46-45b1-b615-c8626ac98287",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "# Actual test data\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=test_df.index,\n",
    "    y=test_df['Load_MW'],\n",
    "    name='Actual Load',\n",
    "    line=dict(color='black', width=2)\n",
    "))\n",
    "\n",
    "# SARIMAX prediction\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=test_df.index,\n",
    "    y=sarimax_forecast,\n",
    "    name='SARIMAX Forecast',\n",
    "    line=dict(color='red', width=2, dash='dash')\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='SARIMAX Forecast vs Actual Load (30-Day Test Period)',\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='Load (MW)',\n",
    "    hovermode='x unified',\n",
    "    height=500\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(\"‚úì SARIMAX visualization complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf57bd4-5867-4743-ac94-a536787ad09b",
   "metadata": {},
   "source": [
    "# SECTION 9: MODEL COMPARISON AND EVALUATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5201c8cb-6bd0-43bc-b270-0481df1d0668",
   "metadata": {
    "tags": []
   },
   "source": [
    "COMPARING PROPHET VS SARIMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dded63e3-a31b-4eeb-a882-3fc1ec89d958",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract predictions\n",
    "prophet_pred = prophet_forecast['yhat'].values\n",
    "sarimax_pred = sarimax_forecast.values\n",
    "actual = test_df['Load_MW'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdecf01d-18ec-4fad-ade7-ff50118a80d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "def calculate_metrics(actual, predicted, model_name):\n",
    "    \"\"\"Calculate and display performance metrics\"\"\"\n",
    "    mae = mean_absolute_error(actual, predicted)\n",
    "    rmse = np.sqrt(mean_squared_error(actual, predicted))\n",
    "    mape = np.mean(np.abs((actual - predicted) / actual)) * 100\n",
    "    \n",
    "    print(f\"\\n{model_name} Performance:\")\n",
    "    print(f\"   MAE (Mean Absolute Error): {mae:.2f} MW\")\n",
    "    print(f\"   RMSE (Root Mean Squared Error): {rmse:.2f} MW\")\n",
    "    print(f\"   MAPE (Mean Absolute Percentage Error): {mape:.2f}%\")\n",
    "    \n",
    "    return {'MAE': mae, 'RMSE': rmse, 'MAPE': mape}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd0aaad-f922-4487-82f3-5f6ce478cc79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate metrics for both models\n",
    "prophet_metrics = calculate_metrics(actual, prophet_pred, \"PROPHET\")\n",
    "sarimax_metrics = calculate_metrics(actual, sarimax_pred, \"SARIMAX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d4aa6d-22c4-4347-8095-aabbccc2c1a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create comparison table\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Prophet': prophet_metrics,\n",
    "    'SARIMAX': sarimax_metrics\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1007cf-cd15-417f-9dcf-0c3cd892b686",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Determine winner\n",
    "if prophet_metrics['MAPE'] < sarimax_metrics['MAPE']:\n",
    "    winner = \"Prophet\"\n",
    "    difference = sarimax_metrics['MAPE'] - prophet_metrics['MAPE']\n",
    "else:\n",
    "    winner = \"SARIMAX\"\n",
    "    difference = prophet_metrics['MAPE'] - sarimax_metrics['MAPE']\n",
    "\n",
    "print(f\"\\nüèÜ WINNER: {winner}\")\n",
    "print(f\"   Better by {difference:.2f}% MAPE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d32ee9-ca11-40d1-8fc4-a2ec05a954a2",
   "metadata": {},
   "source": [
    "### 9.1: Side-by-Side Comparison Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51b0795-a87c-4da4-9006-7796262d297e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "# Actual data\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=test_df.index,\n",
    "    y=actual,\n",
    "    name='Actual Load',\n",
    "    line=dict(color='black', width=2.5)\n",
    "))\n",
    "\n",
    "# Prophet forecast\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=test_df.index,\n",
    "    y=prophet_pred,\n",
    "    name='Prophet Forecast',\n",
    "    line=dict(color='blue', width=2, dash='dash')\n",
    "))\n",
    "\n",
    "# SARIMAX forecast\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=test_df.index,\n",
    "    y=sarimax_pred,\n",
    "    name='SARIMAX Forecast',\n",
    "    line=dict(color='red', width=2, dash='dot')\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Model Comparison: Prophet vs SARIMAX vs Actual Load',\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='Load (MW)',\n",
    "    hovermode='x unified',\n",
    "    height=600,\n",
    "    legend=dict(x=0.01, y=0.99)\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(\"‚úì Comparison visualization complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7bd671-0c47-483b-bdab-805903bef918",
   "metadata": {},
   "source": [
    "### 9.2 Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f6e505-c08a-4b7e-9335-12d62c7fe1b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate errors\n",
    "prophet_errors = actual - prophet_pred\n",
    "sarimax_errors = actual - sarimax_pred\n",
    "\n",
    "# Create error distribution plot\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    subplot_titles=('Prophet Errors', 'SARIMAX Errors')\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Histogram(x=prophet_errors, name='Prophet', \n",
    "                 marker_color='blue', nbinsx=50),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Histogram(x=sarimax_errors, name='SARIMAX', \n",
    "                 marker_color='red', nbinsx=50),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "fig.update_xaxes(title_text=\"Error (MW)\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"Error (MW)\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"Frequency\", row=1, col=1)\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text=\"Error Distribution Analysis\",\n",
    "    showlegend=False,\n",
    "    height=400\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(\"‚úì Error analysis complete!\")\n",
    "print(\"\\nError Insights:\")\n",
    "print(f\"   Prophet Error Std Dev: {np.std(prophet_errors):.2f} MW\")\n",
    "print(f\"   SARIMAX Error Std Dev: {np.std(sarimax_errors):.2f} MW\")\n",
    "print(f\"   Prophet Error Mean: {np.mean(prophet_errors):.2f} MW\")\n",
    "print(f\"   SARIMAX Error Mean: {np.mean(sarimax_errors):.2f} MW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3bcead-1184-41cd-ab76-4aa9a3f36d9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
